---
title: "Summer 2021"
date: Wed Jun 16 21:52:01 EDT 2021
description: "Details, notes, and questions from the Summer 2021 Reading Group."
---

## Session 1

**Date**:
June 16 8:30PM EDT/June 17 8:30AM HKT

**Reading**:
Bender, et al. (2021) [On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)

**Questions and Discussion Points:**

Model Architectures
- How do 1-shot and 0-shot learning work?
- How important is attention in model training?
- How do multilingual models work?
- What are some good approaches for multiple machine learning models working together?

"Good Models"
- What are some different ways of scoring machine learning models?
- Is there a way to make toxicity scoring work better?
- When is a machine learning model too small? Is there such a thing?

Data Sourcing
- What are the economies of training data?
- If not the internet, where is a better place to get data?

Energy Efficiency
- How can machine learning be made more energy efficient?
- Is there a more efficient way to do consensus (e.g. emergent consensus)?

Distributed Systems
- What is a distributed system?
- What are the foundations of distributed systems?
- What are the roots of consensus algorithms?
- How is reinforcement learning used in distributed systems?
- What is an "intelligent distributed system"?


## Session 2

**Date**:
June 23 8:30PM EDT/June 24 8:30AM HKT

**Reading**:
Lamport, Leslie. "The part-time parliament." Concurrency: the Works of Leslie Lamport. 2019. 277-317.

**Questions and Discussion Points:**

tbd